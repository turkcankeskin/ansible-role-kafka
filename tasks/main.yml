---
- name: Check if required variables are defined
  ansible.builtin.assert:
    that:
      - kafka_node_id is defined
      - kafka_opts | type_debug == "list" or kafka_opts | type_debug == "AnsibleUnicode"

- name: Update apt cache
  become: true
  ansible.builtin.apt:
    update_cache: true
    cache_valid_time: 3600
  when: ansible_os_family == "Debian" and kafka_install_dependencies | bool

  # acl package is required to set correct permissions when using become_user
- name: Install acl package
  become: true
  ansible.builtin.package:
    name: acl
    state: present
  when: kafka_install_dependencies | bool and ansible_os_family == "Debian"

- name: Install java
  become: true
  ansible.builtin.package:
    name: "{{ kafka__dependencies }}"
    state: present
  when: kafka_install_dependencies | bool

- name: Ensure Kafka group exists
  become: true
  ansible.builtin.group:
    name: "{{ kafka_user_group }}"
    state: present
    system: true

- name: Ensure Kafka user exists
  become: true
  ansible.builtin.user:
    name: "{{ kafka_user }}"
    state: present
    system: true
    group: "{{ kafka_user_group }}"
    home: "{{ kafka_home }}"
    createhome: false

- name: Get checksum
  ansible.builtin.uri:
    url: https://downloads.apache.org/kafka/{{ kafka_version }}/kafka_{{ kafka_scala_version }}-{{ kafka_version }}.tgz.sha512
    return_content: true
  retries: 3
  delay: 3
  register: kafka__reg_checksum
  run_once: true
  when: kafka_checksum is not defined

- name: Set checksum
  ansible.builtin.set_fact:
    kafka_checksum: "{{ kafka__reg_checksum.content \
      | replace('\n', '') \
      | regex_replace('\\s{2,}', ' ') \
      | replace('kafka_' + kafka_scala_version | string + '-' + kafka_version | string + '.tgz: ', 'sha512:') }}"
  when: kafka_checksum is not defined

- name: Download Kafka
  become: true
  ansible.builtin.get_url:
    url: "{{ kafka__download_url }}"
    checksum: "{{ kafka_checksum }}"
    dest: "{{ kafka__download_destination }}"
    mode: "0644"
    timeout: 30
  retries: 3
  delay: 3

- name: Unpack Kafka
  become: true
  ansible.builtin.unarchive:
    src: "{{ kafka__download_destination }}"
    copy: false
    dest: "{{ kafka_download_directory }}"
    owner: "{{ kafka_user }}"
    group: "{{ kafka_user_group }}"

- name: Configure Kafka symlink
  become: true
  ansible.builtin.file:
    path: "{{ kafka_home }}"
    src: "{{ kafka_download_directory }}/kafka_{{ kafka_scala_version }}-{{ kafka_version }}"
    state: link
    force: true
    follow: false

- name: Create Kafka data and log directories
  become: true
  ansible.builtin.file:
    path: "{{ item }}"
    state: directory
    owner: "{{ kafka_user }}"
    group: "{{ kafka_user_group }}"
    mode: "0750"
  loop: "{{ kafka_log_dirs + [kafka_log_directory] }}"

- name: Directing Kafka service logs to /var/log
  become: true
  ansible.builtin.file:
    path: "{{ kafka_home }}/logs"
    src: "{{ kafka_log_directory }}"
    state: link

- name: Ensure sysconfig directory exists
  become: true
  ansible.builtin.file:
    path: /etc/sysconfig
    state: directory
    mode: "0755"

- name: Allow Kafka ports 9091, 9092, 9093 with UFW
  become: true
  ansible.builtin.ufw:
    rule: allow
    port: "{{ item }}"
    proto: tcp
  loop:
    - 9091
    - 9092
    - 9093
    - 12345

- name: Download Prometheus JMX exporter javaagent
  become: true
  ansible.builtin.get_url:
    url: https://github.com/prometheus/jmx_exporter/releases/download/1.3.0/jmx_prometheus_javaagent-1.3.0.jar
    dest: /opt/kafka/libs/jmx_prometheus_javaagent-1.3.0.jar
    mode: "0644"

- name: Create jmx_exporter.yml config
  become: true
  ansible.builtin.copy:
    dest: /opt/kafka/config/jmx_exporter.yml
    content: |
      rules:
        - pattern: ".*"
    owner: "{{ kafka_user }}"
    group: "{{ kafka_user_group }}"
    mode: "0644"

- name: Ensure KAFKA_JMX_OPTS is set after shebang in kafka-server-start.sh
  become: true
  ansible.builtin.lineinfile:
    path: /opt/kafka/bin/kafka-server-start.sh
    insertafter: '^#!.*'
    line: export KAFKA_JMX_OPTS="-javaagent:/opt/kafka/libs/jmx_prometheus_javaagent-1.3.0.jar=9091:/opt/kafka/config/jmx_exporter.yml -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=12345 -Dcom.sun.management.jmxremote.rmi.port=12345 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname={{ ansible_host }}"
    state: present
    create: false
    
- name: Configure kafka heap size
  become: true
  ansible.builtin.lineinfile:
    regexp: "^KAFKA_HEAP_OPTS"
    line: KAFKA_HEAP_OPTS="-Xmx{{ kafka_heap_size }} -Xms{{ kafka_heap_size }}"
    dest: /etc/sysconfig/kafka
    mode: "0644"
    create: true
  notify: Restart Kafka

- name: Configure kafka opts
  become: true
  ansible.builtin.lineinfile:
    regexp: "^KAFKA_OPTS"
    line: KAFKA_OPTS="{{ kafka__opts }}"
    dest: /etc/sysconfig/kafka
    mode: "0644"
    create: true
  notify: Restart Kafka

- name: Install Kafka service definition
  become: true
  ansible.builtin.template:
    src: kafka.service.j2
    dest: /usr/lib/systemd/system/kafka.service
    mode: "0644"
  notify: Restart Kafka

- name: Add controller nodes to group
  ansible.builtin.add_host:
    name: "{{ hostvars[item]['inventory_hostname'] }}"
    group: kafka__group_controller_nodes
  when: "'controller' in hostvars[item]['kafka_node_roles'] | default(kafka_node_roles)"
  loop: "{{ ansible_play_hosts }}"
  changed_when: false
  loop_control:
    label: "{{ hostvars[item]['inventory_hostname'] }}"

- name: Add broker nodes to group
  ansible.builtin.add_host:
    name: "{{ hostvars[item]['inventory_hostname'] }}"
    group: kafka__group_broker_nodes
  when: "'broker' in hostvars[item]['kafka_node_roles'] | default(kafka_node_roles)"
  loop: "{{ ansible_play_hosts }}"
  changed_when: false
  loop_control:
    label: "{{ hostvars[item]['inventory_hostname'] }}"

- name: Configure Kafka
  become: true
  become_user: "{{ kafka_user }}"
  ansible.builtin.template:
    src: server.properties.j2
    dest: "{{ kafka__config_path }}"
    mode: "0644"
  notify: Restart Kafka

- name: Check if data directory is formatted
  become: true
  become_user: "{{ kafka_user }}"
  ansible.builtin.stat:
    path: "{{ item }}/meta.properties"
  register: kafka__reg_check_if_formatted
  loop: "{{ kafka_log_dirs }}"

- name: Check if cluster uuid lock file exists
  become: true
  become_user: "{{ kafka_user }}"
  ansible.builtin.stat:
    path: "{{ kafka__uuid_file }}"
  register: kafka__reg_check_uuid_file
  delegate_to: "{{ groups['kafka__group_controller_nodes'] | first }}"
  run_once: true

- name: Create cluster uuid
  become: true
  become_user: "{{ kafka_user }}"
  ansible.builtin.command:
    cmd: "{{ kafka_home }}/bin/kafka-storage.sh random-uuid"
  register: kafka__reg_storage_random_uuid
  changed_when: true
  delegate_to: "{{ groups['kafka__group_controller_nodes'] | first }}"
  when: not kafka__reg_check_uuid_file.stat.exists
  run_once: true

- name: Write cluster uuid
  become: true
  become_user: "{{ kafka_user }}"
  ansible.builtin.copy:
    content: "{{ kafka__reg_storage_random_uuid.stdout }}"
    dest: "{{ kafka__uuid_file }}"
    mode: "0444"
  when: not kafka__reg_check_uuid_file.stat.exists and inventory_hostname in groups["kafka__group_controller_nodes"]

- name: Get cluster uuid
  become: true
  become_user: "{{ kafka_user }}"
  ansible.builtin.command:
    cmd: cat {{ kafka__uuid_file }}
  delegate_to: "{{ groups['kafka__group_controller_nodes'] | first }}"
  register: kafka__reg_cluster_uuid
  changed_when: false
  run_once: true

- name: Set cluster uuid
  become: true
  become_user: "{{ kafka_user }}"
  ansible.builtin.set_fact:
    kafka_cluster_id: "{{ kafka__reg_cluster_uuid.stdout }}"

- name: Format kafka log directory
  become: true
  become_user: "{{ kafka_user }}"
  ansible.builtin.command:
    cmd: >
      {{ kafka_home }}/bin/kafka-storage.sh format
      --config {{ kafka__config_path }}
      --cluster-id {{ kafka_cluster_id }}
  changed_when: true
  when: not kafka__reg_check_if_formatted.results[0].stat.exists

- name: Ensure meta.properties and bootstrap.checkpoint are owned by kafka user
  become: true
  ansible.builtin.file:
    path: "{{ item }}"
    owner: "{{ kafka_user }}"
    group: "{{ kafka_user_group }}"
    mode: "0600"
  loop:
    - "{{ kafka_log_dirs[0] }}/meta.properties"
    - "{{ kafka_log_dirs[0] }}/bootstrap.checkpoint"
  ignore_errors: true
  
- name: Flush handlers
  ansible.builtin.meta: flush_handlers

- name: Ensure Kafka service is enabled and started
  become: true
  ansible.builtin.systemd:
    name: kafka
    enabled: true
    state: started
    daemon_reload: true
  retries: 3
  delay: 2

- name: Wait for Kafka controllers to start
  ansible.builtin.wait_for:
    port: 9093
    host: "{{ ansible_host }}"
    timeout: 30
  when: inventory_hostname in groups["kafka__group_controller_nodes"]

- name: Wait for Kafka brokers to start
  ansible.builtin.wait_for:
    port: 9092
    host: "{{ ansible_host }}"
    timeout: 30
  when: inventory_hostname in groups["kafka__group_broker_nodes"]

- name: limits.conf ayarlarını uygula
  become: true
  ansible.builtin.copy:
    dest: /etc/security/limits.conf
    content: |
      * hard maxlogins 10
      * hard core 0
      * soft nproc 512
      * hard nproc 1024

      # Kafka user limit 
      kafka           soft    nofile          unlimited
      kafka           hard    nofile          unlimited
      kafka           soft    nproc           unlimited
      kafka           hard    nproc           unlimited

      # root user limit
      root            soft    nofile          95000
      root            hard    nofile          95000
      root            soft    nproc           95000
      root            hard    nproc           95000

      # End of file
    owner: root
    group: root
    mode: '0644'

- name: sysctl.conf os
  become: true
  ansible.builtin.copy:
    dest: /etc/sysctl.conf
    content: >
      # /etc/sysctl.conf - Linux kernel sysctl for kafka application
      {% for key, value in kafka_sysctl_conf.items() %}
      {{ key | replace('_', '.') }} = {{ value }}
      {% endfor %}
    owner: root
    group: root
    mode: '0644'
  notify: sysctl_reload

- name: Temp set listener to PLAINTEXT
  become: true
  ansible.builtin.lineinfile:
    path: "{{ kafka__config_path }}"
    regexp: '^listeners='
    line: "listeners=PLAINTEXT://{{ ansible_host }}:9092,CONTROLLER://{{ ansible_host }}:9093"
    backrefs: yes
  when:
    - kafka_security.enabled | default(false)
    - kafka_security.sasl_mechanism == 'SCRAM-SHA-256'
    - kafka_security.users is defined
    - inventory_hostname in groups['kafka__group_broker_nodes']

- name: Temp set inter.broker.listener.name to PLAINTEXT
  become: true
  ansible.builtin.lineinfile:
    path: "{{ kafka__config_path }}"
    regexp: '^inter.broker.listener.name='
    line: "inter.broker.listener.name=PLAINTEXT"
    backrefs: yes
  when:
    - kafka_security.enabled | default(false)
    - kafka_security.sasl_mechanism == 'SCRAM-SHA-256'
    - kafka_security.users is defined
    - inventory_hostname in groups['kafka__group_broker_nodes']

- name: Temp set advertised.listeners to PLAINTEXT
  become: true
  ansible.builtin.lineinfile:
    path: "{{ kafka__config_path }}"
    regexp: '^advertised.listeners='
    line: "advertised.listeners=PLAINTEXT://{{ ansible_host }}:9092"
    backrefs: yes
  when:
    - kafka_security.enabled | default(false)
    - kafka_security.sasl_mechanism == 'SCRAM-SHA-256'
    - kafka_security.users is defined
    - inventory_hostname in groups['kafka__group_broker_nodes']

- name: Temp set listener.security.protocol.map to PLAINTEXT
  become: true
  ansible.builtin.lineinfile:
    path: "{{ kafka__config_path }}"
    regexp: '^listener.security.protocol.map='
    line: "listener.security.protocol.map=PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT"
    backrefs: yes
  when:
    - kafka_security.enabled | default(false)
    - kafka_security.sasl_mechanism == 'SCRAM-SHA-256'
    - kafka_security.users is defined
    - inventory_hostname in groups['kafka__group_broker_nodes']

- name: Kafka service restart (PLAINTEXT ile)
  become: true
  ansible.builtin.systemd:
    name: kafka
    state: restarted
  when:
    - kafka_security.enabled | default(false)
    - kafka_security.sasl_mechanism == 'SCRAM-SHA-256'
    - kafka_security.users is defined
    - inventory_hostname in groups['kafka__group_broker_nodes']

- name: Create Kafka SCRAM users on all brokers (PLAINTEXT)
  become: true
  become_user: "{{ kafka_user }}"
  ansible.builtin.shell: |
    {{ kafka_home }}/bin/kafka-configs.sh --bootstrap-server {{ ansible_host }}:9092 \
    --alter --add-config 'SCRAM-SHA-256=[iterations=4096,password={{ item.password }}]' \
    --entity-type users --entity-name {{ item.name }}
  loop: "{{ kafka_security.users }}"
  when:
    - kafka_security.enabled | default(false)
    - kafka_security.sasl_mechanism == 'SCRAM-SHA-256'
    - kafka_security.users is defined
    - inventory_hostname in groups['kafka__group_broker_nodes']
  changed_when: true
  retries: 5
  delay: 10
  register: scram_user_result
  until: scram_user_result is succeeded

- name: Listener set SASL_PLAINTEXT
  become: true
  ansible.builtin.lineinfile:
    path: "{{ kafka__config_path }}"
    regexp: '^listeners='
    line: "listeners=SASL_PLAINTEXT://{{ ansible_host }}:9092,CONTROLLER://{{ ansible_host }}:9093"
    backrefs: yes
  when:
    - kafka_security.enabled | default(false)
    - kafka_security.sasl_mechanism == 'SCRAM-SHA-256'
    - kafka_security.users is defined
    - inventory_hostname in groups['kafka__group_broker_nodes']

- name: inter.broker.listener.name set to SASL_PLAINTEXT
  become: true
  ansible.builtin.lineinfile:
    path: "{{ kafka__config_path }}"
    regexp: '^inter.broker.listener.name='
    line: "inter.broker.listener.name=SASL_PLAINTEXT"
    backrefs: yes
  when:
    - kafka_security.enabled | default(false)
    - kafka_security.sasl_mechanism == 'SCRAM-SHA-256'
    - kafka_security.users is defined
    - inventory_hostname in groups['kafka__group_broker_nodes']

- name: advertised.listeners set to SASL_PLAINTEXT
  become: true
  ansible.builtin.lineinfile:
    path: "{{ kafka__config_path }}"
    regexp: '^advertised.listeners='
    line: "advertised.listeners=SASL_PLAINTEXT://{{ ansible_host }}:9092"
    backrefs: yes
  when:
    - kafka_security.enabled | default(false)
    - kafka_security.sasl_mechanism == 'SCRAM-SHA-256'
    - kafka_security.users is defined
    - inventory_hostname in groups['kafka__group_broker_nodes']

- name: listener.security.protocol.map set to SASL_PLAINTEXT
  become: true
  ansible.builtin.lineinfile:
    path: "{{ kafka__config_path }}"
    regexp: '^listener.security.protocol.map='
    line: "listener.security.protocol.map=SASL_PLAINTEXT:SASL_PLAINTEXT,CONTROLLER:PLAINTEXT"
    backrefs: yes
  when:
    - kafka_security.enabled | default(false)
    - kafka_security.sasl_mechanism == 'SCRAM-SHA-256'
    - kafka_security.users is defined
    - inventory_hostname in groups['kafka__group_broker_nodes']

- name: Kafka service restart SASL_PLAINTEXT
  become: true
  ansible.builtin.systemd:
    name: kafka
    state: restarted
  when:
    - kafka_security.enabled | default(false)
    - kafka_security.sasl_mechanism == 'SCRAM-SHA-256'
    - kafka_security.users is defined
    - inventory_hostname in groups['kafka__group_broker_nodes']

- name: Create /opt/kafka/client.properties for SCRAM user
  become: true
  ansible.builtin.copy:
    dest: /opt/kafka/client.properties
    content: |
      sasl.mechanism=SCRAM-SHA-256
      security.protocol=SASL_PLAINTEXT
      sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username="{{ kafka_security.users[0].name }}" password="{{ kafka_security.users[0].password }}";
    owner: root
    group: root
    mode: '0644'
  when:
    - kafka_security.enabled | default(false)
    - kafka_security.sasl_mechanism == 'SCRAM-SHA-256'
    - kafka_security.users is defined

- name: Fetch Kafka topics
  become: true
  become_user: "{{ kafka_security.users[0].name | default(kafka_user) }}"
  ansible.builtin.command:
    cmd: "{{ kafka_home }}/bin/kafka-topics.sh --bootstrap-server {{ ansible_host }}:9092 --command-config /opt/kafka/client.properties --list"
  register: kafka__reg_topics
  changed_when: false
  check_mode: false
  delegate_to: "{{ groups['kafka__group_broker_nodes'] | first }}"
  run_once: true

- name: Create kafka topics
  become: true
  become_user: "{{ kafka_security.users[0].name | default(kafka_user) }}"
  ansible.builtin.command:
    cmd: >
      {{ kafka_home }}/bin/kafka-topics.sh --create --bootstrap-server {{ ansible_host }}:9092 --command-config /opt/kafka/client.properties --topic {{ item.name }}
      --partitions {{ item.partitions | default(1) }}
      --replication-factor {{ item.replication_factor | default(1) }}
      {% for k, v in item.config | default({}) | dictsort %}
      --config {{ k | replace("_", ".") }}={{ v }}
      {% endfor %}
  loop: "{{ kafka_topics }}"
  when: item.name is defined and (kafka__reg_topics.stdout_lines is not defined or item.name not in kafka__reg_topics.stdout_lines)
  changed_when: true
  delegate_to: "{{ groups['kafka__group_broker_nodes'] | first }}"
  run_once: true
  loop_control:
    label: "{{ item.name }}"
  failed_when: >
    (result.rc != 0 and
     'TopicExistsException' not in result.stderr and
     'already exists' not in result.stdout)
  register: result
